好的，下面是我为你准备的《信息技术基础》课程中“数据预处理”部分的Quarto Reveal.js幻灯片文档（.qmd文件）。我将内容分成了几个部分，请按照顺序复制到你的.qmd文件中。

**第一部分：文档头和设置**

```qmd
---
title: "数据分析理论与Python实战"
subtitle: "第三章 数据预处理<br>不了解数据一切都是空谈"
author: "XXX 教授"
institute: "XXX大学商学院"
format:
  revealjs:
    theme: [sky] 
    slide-number: true
    show-slide-number: all
    preview-links: auto
    footer: "数据预处理"
---
```

**第二部分：标题页和目录**

```qmd
## 

::: {layout-ncol=2}
![](images/cover.png){#fig-cover}

:::{.notes}
大家好，欢迎来到《数据分析理论与Python实战》课程。今天我们将一起学习第三章：数据预处理。

正如标题所说，“不了解数据一切都是空谈”。在数据分析中，数据预处理是非常关键的一步，它直接影响到后续分析结果的质量。
:::
:::

## 目录

- 了解数据 🧐
- 数据质量评估 🔍
- 数据清洗 🧼
- 特征工程 🛠️

:::{.notes}
本章我们将围绕以下四个方面展开：

1.  **了解数据**：我们将学习数据的分类、特征以及如何描述数据。
2.  **数据质量评估**：我们将了解如何评估数据的完整性、一致性、准确性和及时性。
3.  **数据清洗**：我们将学习如何处理缺失值、噪声数据、不一致数据和异常数据。
4.  **特征工程**：我们将学习如何从原始数据中提取有用的特征。
:::
```


## 了解数据

- 数据的分类 📊
- 数据的特征 📈

:::{.notes}
首先，我们来深入了解一下数据。我们需要知道数据有哪些类型，以及如何描述数据的特征。这就像认识一个新朋友，我们要了解他的基本信息和性格特点。😊
:::

## 了解数据 - 数据的分类

::: {layout-ncol=2}
```{mermaid}
%%| echo: false
flowchart TD
    A[数据 📦] --> B(定量数据 🔢)
    A --> C(定性数据 🔤)
    B --> D(离散变量 🎲)
    B --> E(连续变量 📏)
    C --> F(定序变量 🥇🥈🥉)
    C --> G(名义变量 ♂️♀️)
```

:::{.callout-note appearance="simple"}
**定量数据 (Quantitative Data)** 🔢

- 可以测量，用数字表示。
- **离散变量 (Discrete Variable)** 🎲：
    - 取值是有限个或可数无限个，通常是整数。
    - 例如：客户数量、产品数量、不良品个数。
    -  **举例**：一个商店一天卖出的苹果数量🍎可能是10个、25个或50个，但不会是10.5个。
- **连续变量 (Continuous Variable)** 📏：
    - 取值可以是某个区间内的任意值，通常是带有小数点的数值。
    - 例如：身高、体重、收入、温度。
     - **举例**：一个人的身高🧍可能是1.75米，体重可能是68.5公斤。
:::

:::{.callout-note appearance="simple"}
**定性数据 (Qualitative Data)** 🔤

- 描述事物的性质或类别，通常用文字表示。
- **定序变量 (Ordinal Variable)** 🥇🥈🥉：
    - 类别之间有顺序关系，但不能进行数值运算。
    - 例如：教育程度（小学、初中、高中、大学）、满意度（非常满意、满意、一般、不满意、非常不满意）。
    - **举例**：比赛中获得的奖牌🏅有金牌、银牌、铜牌，它们之间有等级顺序，但我们不能说金牌比银牌“好多少”。
- **名义变量 (Nominal Variable)** ♂️♀️：
    - 类别之间没有顺序关系，也不能进行数值运算。
    - 例如：性别（男、女）、颜色（红、黄、蓝）、血型（A型、B型、AB型、O型）。
    - **举例**：人的性别🚹🚺有男和女，它们之间没有等级或顺序关系。
:::
:::

:::{.notes}
数据的分类是数据分析的基础。我们可以将数据分为两大类：定量数据和定性数据。就像把水果🍎和蔬菜🥬分开一样。

**定量数据**是可以测量的，用数字表示。就像测量身高📏和体重⚖️一样。定量数据又可以分为离散变量和连续变量。

**定性数据**描述的是事物的性质或类别，通常用文字表示。就像描述一个人的性格😎或爱好🎨一样。定性数据又可以分为定序变量和名义变量。

理解数据的分类有助于我们选择合适的分析方法。就像选择合适的工具🛠️来修理不同的东西一样。
:::

## 了解数据 - 数据的分类：定性数据 (续)

::: {layout-ncol=2}
- **定序变量 (Ordinal Variable)** 🥇🥈🥉

    -   只对某些特性的“多少”进行排序。
    -   例如：对事物进行评价，将其分为“好”、“一般”、“不好”三个等级，其等级之间没有定量关系。
    -   **举例**：
        -   满意度调查（非常满意、满意、一般、不满意、非常不满意）😊😐🙁
        -   信用评级（AAA、AA、A、BBB、BB、B、CCC、CC、C）
        -   教育程度（小学、初中、高中、大学）

- **名义变量 (Nominal Variable)** ♂️♀️

    -   只测量某种特征的出现或者不出现。
    -   例如：性别“男”和“女”，两者之间没有任何关系，不能排序或者刻度化。
    -   **举例**：
        -   血型（A型、B型、AB型、O型）🅰️🅱️🆎🅾️
        -   职业（教师、医生、工程师、工人）👨‍🏫👩‍⚕️👨‍💻👷
        -   颜色（红、黄、蓝、绿）🔴🟡🔵🟢
:::

## 了解数据 - 数据的特征

- **集中趋势 (Central Tendency)** 🎯
    - 主要测度：均值、中位数、众数。
    - 对于定性数据而言，这三个指标所能提供的信息很少。
    - 对于定序变量，均值无意义，中位数和众数能反映一定的含义；
    - 对于名义变量，均值和中位数均无意义，仅众数有一定的含义，但仍需注意，众数仅代表对应的特征出现的最
      多，但不能代表该特征占多数。其中，特别的是，对于
      名义变量的二分变量，如果有合适的取值，均值就可以
      进行有意义的解释。

:::{.notes}
了解了数据的分类，我们再来看看如何描述数据的特征。这就像描述一个人的外貌特征🧔和性格特征😎一样。

首先是集中趋势，它描述了数据集中在哪个位置。就像射箭🎯一样，看箭射中的位置是否集中在靶心🎯。常用的测度有均值、中位数和众数。
:::

## 了解数据 - 数据的特征：集中趋势详解

::: {layout-ncol=2}
| 测度     | 定义                                       | 适用数据类型             | 优点                                       | 缺点                                                         |
| -------- | ------------------------------------------ | ------------------------ | ------------------------------------------ | ------------------------------------------------------------ |
| 均值     | 所有数据值的总和除以数据个数               | 定量数据                 | 容易计算，考虑了所有数据值                   | 容易受极端值影响                                             |
| 中位数   | 将数据按大小排序后，位于中间位置的数值     | 定量数据、定序数据       | 不受极端值影响                             | 不能反映所有数据值的信息                                     |
| 众数     | 数据中出现次数最多的数值                   | 定量数据、定序数据、名义数据 | 不受极端值影响，适用于所有数据类型           | 可能有多个众数，或者没有众数，不能反映所有数据值的信息         |
:::

:::{.callout-note appearance="simple"}
**举例：**

假设有一组学生的考试成绩：70, 75, 80, 85, 90, 95, 100

-   **均值**：(70+75+80+85+90+95+100)/7 = 85
-   **中位数**：85 (中间位置的数值)
-   **众数**：没有众数 (每个数值都只出现一次)

如果有一个学生的成绩是500，那么：

-   **均值**：(70+75+80+85+90+95+500)/7 = 142.14 (受极端值500的影响，均值变得很高)
-   **中位数**：85 (不受极端值影响)
-   **众数**：没有众数
:::

:::{.notes}
让我们更详细地了解一下集中趋势的三个测度：

-   **均值**：就像求平均分一样，把所有数值加起来，再除以数值的个数。
-   **中位数**：就像把所有人按身高从矮到高排队🧍🧍🧍🧍🧍，站在最中间那个人的身高就是中位数。
-   **众数**：就像投票🗳️一样，得票最多的那个选项就是众数。

需要注意的是，不同的数据类型适用不同的集中趋势测度。
:::

## 了解数据 - 数据的特征

- **离散程度 (Dispersion)** 📏↔️
    - 常见的测度有极差、方差和标准差，另外，还有四分位距、平均差和变异系数等。
    - **定量数据**：极差代表数据所处范围的大小，方差、标准差和平均差等代表
      数据相对均值的偏离情况，但是方差、标准差和平均差等都是
      数值的绝对量，无法规避数值度量单位的影响，变异系数为了
      修正这个弊端，使用标准差除以均值得到的一个相对量来反映
      数据集的变异情况或者离散程度。
    - **定性数据**：极差代表取值类别，相比定量数据，定性数据的极差所表达的
      含义很有限，剩余的离散程度的测度对于定性数据的含义不大，
      尤其是名义变量。

:::{.notes}
除了集中趋势，我们还需要了解数据的离散程度，它描述了数据之间的差异程度。就像测量一组人的身高差异🚶🧍🚶‍♀️一样，是高矮悬殊还是比较接近。
:::

## 数据的特征--离散程度的常用指标
::: {layout-ncol=2}
| 指标       | 定义                                                         | 优点                               | 缺点                                                           |
| ---------- | ------------------------------------------------------------ | ---------------------------------- | -------------------------------------------------------------- |
| 极差       | 数据集中的最大值与最小值之差                                 | 计算简单                           | 易受极端值影响，不能反映数据分布情况                           |
| 方差       | 每个数据值与均值之差的平方的平均值                           | 考虑了所有数据值，反映数据离散程度 | 单位是数据单位的平方，不易解释                                 |
| 标准差     | 方差的平方根                                                   | 考虑了所有数据值，反映数据离散程度 | 单位与数据单位相同，易于解释                                   |
| 四分位距   | 上四分位数与下四分位数之差                                   | 不受极端值影响                     | 不能反映所有数据值的信息                                       |
| 平均差     | 每个数据值与均值之差的绝对值的平均值                         | 考虑了所有数据值，反映数据离散程度 | 计算相对复杂                                                   |
| 变异系数   | 标准差除以均值                                                 | 无量纲，可用于比较不同数据集的离散程度 | 当均值接近于0时，变异系数可能很大，失去意义                    |
:::

:::{.callout-note appearance="simple"}
**举例：**

假设有两组数据：

-   A组：1, 2, 3, 4, 5
-   B组：1, 1, 3, 5, 5

它们的均值都是3，但离散程度不同：

-   A组：极差=4, 方差=2, 标准差≈1.41, 四分位距=3, 平均差=1.2, 变异系数≈0.47
-   B组：极差=4, 方差=3.2, 标准差≈1.79, 四分位距=4, 平均差=1.6, 变异系数≈0.60

可以看到，B组的离散程度比A组大。
:::

## 了解数据 - 数据的特征

- **相关性测量 (Correlation Measurement)** 🤝
    - 数据可视化处理：通过折线图或者散点图，做图表相关分析，可以对相关关系有一个初步的探索和认识。
      - **举例**：我们可以画出气温🌡️和冰淇淋销量🍦的折线图，看看它们之间是否有关系。
    - 计算变量间的协方差：可以确定相关关系的正负，没有任何关于关系强度的信息，如果变量的测量单位发生变化，这一统计量的值就会发生变化，但是实际变量间的相关关系并没有发生变化。
    - 计算变量间的相关系数：相关系数则是一个不受测量单位影响的相关关系统计量，理论上限是+1（或-1），表示完全线性相关。
       - **举例**：我们可以计算身高🧍和体重⚖️的相关系数，看看它们之间有多大的关联。
    - 进行一元回归或多元回归分析：
       - **举例**：我们可以建立一个模型，用广告投入💰来预测销售额📈。

:::{.notes}
我们还可以测量数据之间的相关性，了解一个变量的变化是否与另一个变量的变化有关。就像研究朋友之间的关系一样，看看他们是否经常一起玩耍🤹。
:::

## 了解数据 - 数据的特征：相关性可视化

```{python}
#| echo: false
#| label: fig-correlation-plot
#| fig-cap: "相关性可视化示例"
#| fig-alt: "一个散点图，显示了两个变量之间的正相关关系。"

import matplotlib.pyplot as plt
import numpy as np

# 生成模拟数据
np.random.seed(42)
x = np.random.rand(50) * 10
y = 2 * x + 1 + np.random.randn(50) * 2

# 绘制散点图
plt.figure(figsize=(8, 6))
plt.scatter(x, y)
plt.xlabel("变量 X")
plt.ylabel("变量 Y")
plt.title("相关性可视化")
plt.show()
```

:::{.notes}
这是一个相关性可视化的例子。我们可以看到，随着变量X的增加，变量Y也趋向于增加，这表明它们之间可能存在正相关关系。
:::

## 了解数据 - 数据的特征

- **数据缺失 (Missing Data)** ❓
    - 将数据集中不含缺失值的变量称为完全变量，含有缺失值的变量称为不完全变量。产生缺失值的原因：
        - 数据本身被遗漏，由于数据采集设备的故障、存储介质的故障、传输媒体的故障、一些人为因素等原因而丢失了；
           -  **举例**：传感器故障📡导致温度数据没有记录下来。
        - 某些对象的的一些属性或者特征是不存在的，所以导致空缺；
           - **举例**：一个人没有填写婚姻状况💑这一栏。
        - 某些信息被认为不重要，与给定环境无关，所以被数据库设计者或者信息采集者忽略。
           - **举例**：在收集客户信息时，可能认为“昵称”👻不重要，就没有收集。
-   **举例**：
    -   客户的收入信息缺失 💸
    -   产品的某些参数缺失 ⚙️
    -   调查问卷中的某些问题没有回答 📝

:::{.notes}
在真实的数据中，经常会遇到数据缺失的情况。就像一本书📚缺了几页一样。我们需要了解数据缺失的原因和类型，以便采取合适的处理方法。
:::
## 了解数据-数据缺失的原因
::: {layout-ncol=2}
| **缺失原因**         | **详细说明**                                                                     | **举例**                                                                                   |
| -------------------- | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ |
| **数据遗漏**         | 由于设备故障、存储介质故障、传输媒体故障、人为因素等原因导致数据丢失。             | 传感器故障导致温度数据丢失；网络中断导致数据传输失败；数据录入员漏填了某个字段。           |
| **属性不存在**       | 某些对象的某些属性或特征本来就不存在。                                             | 一个人没有填写婚姻状况（可能未婚）；一件商品没有填写颜色属性（可能只有一种颜色）。         |
| **信息被忽略**       | 某些信息被认为不重要或与当前环境无关，被数据库设计者或信息采集者忽略。             | 在收集客户信息时，认为“昵称”不重要，没有收集；在调查问卷中，认为某个问题与主题无关，没有设置。 |
:::

## 了解数据 - 数据的特征

- **噪声 (Noise)** 📢
    - 噪声是指被观测的变量的随机误差或方差。用数学形式表示为：
      $$ 观测量(Measurement) = 真实数据(True Data) + 噪声 (Noise) $$
-   **举例**：
    -   测量仪器误差 📏
        -   用尺子测量长度时，可能会有轻微的误差。
    -   数据录入错误 ⌨️
        -   把“123”错输成了“132”。
    -   随机干扰 ⚡
        -   在进行无线通信时，可能会受到电磁波的干扰。

:::{.notes}
噪声是指数据中的随机误差或偏差。就像照片上的噪点一样，会影响照片的清晰度。我们需要识别和处理噪声，以减少其对分析结果的影响。
:::

## 了解数据 - 数据的特征

-   **离群点 (Outlier)** 🦄
    -   数据集中包含这样一些数据对象，它们与数据的一般行为或模型不一致，这样的对象被称为离群点。离群点属于观测值
-   **举例**：
    -   信用卡欺诈交易 💳
        -   突然有一笔大额的境外消费。
    -   异常天气事件 🌪️
        -   某地突然出现极端高温或低温。
    -   疾病爆发 🤒
        -   某个地区某种疾病的发病率突然升高。

:::{.notes}
离群点是指与其他数据明显不同的数据点。就像羊群🐑🐑🐑中的一只独角兽🦄一样，非常显眼。我们需要识别和处理离群点，以避免其对分析结果产生误导。
:::

## 数据质量

- 数据分析结果的有效性和准确性的前提保障。💪
- 从哪些方面评估数据质量则是数据分析需要考虑的问题，典型的数据质量标准评估有四个要素：
    - 完整性 (Completeness)
    - 一致性 (Consistency)
    - 准确性 (Accuracy)
    - 及时性 (Timeliness)

:::{.notes}
在进行数据预处理之前，我们需要评估数据的质量。就像在做菜🧑‍🍳之前要检查食材🥬🥕🥩是否新鲜一样。数据质量直接影响到数据分析结果的可靠性。如果数据质量差，就像用坏掉的食材做菜，做出来的菜肯定不好吃🤢。
:::

## 数据质量 - 完整性

- **完整性 (Completeness)** 💯
    - 数据信息是否存在缺失的状况，数据缺失的情况可能是整个数据记录缺失，也可能是数据中某个字段信息的记录缺失。
      - **举例**: 整个数据记录缺失就像人口普查时，漏掉了某个家庭👨‍👩‍👧‍👦的信息；某个字段缺失就像填表时，漏填了某个必填项。
    - 不完整的数据所能借鉴的价值就会大大降低，也是数据质量最为基础的一项评估标准。就像一本书📚缺了几页，会影响阅读体验。
    - 一般使用统计的记录数和唯一值个数统计记录的完整性。网站日志日访问量就是一个记录值，平时的日访问量在1000左
      右，突然某一天降到100了，需要检查一下数据是否存在缺失了。再例如，网站统计地域分布情况的每
      一个地区名就是一个唯一值，我国包括了32个省和直辖市，如果统计得到
      的唯一值小于32，则可以判断数据有可能存在缺失
    - 可以使用统计信息中的空值（NULL）的个数进行审核记录中某个字段的数据缺失。
       - **举例**: 在Python中，我们可以用`pandas`库来统计缺失值：

```{python}
#| echo: true
#| label: code-check-missing
#| code-caption: "检查缺失值"

import pandas as pd
import numpy as np

# 创建一个包含缺失值的DataFrame
data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', None],
        'Age': [25, np.nan, 30, 35, 40],
        'City': ['New York', 'London', 'Paris', np.nan, 'Tokyo']}
df = pd.DataFrame(data)

# 检查缺失值
print(df.isnull().sum())
```

:::{.notes}
完整性是指数据是否缺失。我们需要检查数据中是否存在缺失值，并评估缺失值的比例。就像检查拼图🧩是否缺少了几块一样。
:::

## 数据质量 - 一致性

-   **一致性 (Consistency)** 🔄
    -   一致性是指数据是否合乎规范，数据集合内的数据是否保持了统一的格式
    -   数据质量的一致性主要体现在数据记录的规范和数据是否符合逻辑。
        -   **数据记录的规范**：主要是数据编码和格式，一项数据存在它特定的格式，例如手机号码一定是13位的数字，IP地址一定是由4个0到255间的数字加上”.”组成的，或者一些预先定义的数据约束，比如完整性的非空约束、唯一值约束等。
           - **举例**: 身份证号码的格式、日期的格式（YYYY-MM-DD）等。
        -   **数据是否符合逻辑**：指多项数据间存在着固定的逻辑关系以及一些预先定义的数据约束，例如PV一定是大于等于UV的，跳出率一定是在0到1之间的。
           - **举例**: 年龄不能是负数、身高不能超过3米等。
    -   数据的一致性审核是数据质量审核中比较重要也是比较复杂的一块。就像检查一批产品📦📦📦是否符合相同的规格标准一样。

:::{.notes}
一致性是指数据是否符合规范和逻辑。我们需要检查数据的格式、编码是否一致，以及数据之间是否存在逻辑矛盾。就像检查一批文件📄📄📄的格式是否统一一样。
:::

## 数据质量 - 一致性 (续)
- **举例**:
    - **不一致的日期格式**：
        - 2023-10-26
        - 10/26/2023
        - 26-Oct-2023
    - **不一致的单位**：
        - 温度：有些数据用摄氏度℃，有些数据用华氏度℉。
        - 长度：有些数据用米m，有些数据用英尺ft。
    - **不一致的编码**：
        - 性别：有些数据用“男/女”，有些数据用“M/F”，有些数据用“1/0”。
        - 地区：有些数据用“北京”，有些数据用“北京市”。
    - **逻辑矛盾**：
        - 订单的下单时间晚于发货时间。
        - 用户的年龄大于150岁。
    
- **如何检查一致性**：
    - **定义数据规范**：明确数据的格式、编码、取值范围等。
    - **数据剖析(Data Profiling)**：使用工具或脚本检查数据的格式、分布、统计特征等。
    - **编写校验规则**：根据业务逻辑编写规则，检查数据之间的关系是否合理。
    
:::{.notes}
一致性问题可能有很多种表现形式，我们需要仔细检查才能发现。
:::

## 数据质量 - 准确性

- **准确性 (Accuracy)** ✅
    - 准确性是指数据记录的信息是否存在异常或错误。
    - 准确性关注数据中的错误，例如：
        - 最为常见的数据准确性错误就如乱码。
           - **举例**: 由于编码问题，中文变成了“锟斤拷”�。
        - 异常的大或者小的数据以及不符合有效性要求的数值如访问量Visits一定是整数、年龄一般在1-100之间、转化率一定是介于0到1的值等
           - **举例**: 用户的年龄是-5岁，身高是10米。
    - 数据的准确性可能存在于个别记录，也可能存在于整个数据集
        - 整个数据集的某个字段的数据存在错误，比如常见的数量级的记录错误，这种错误很容易发现，利用Data Profiling的平均数和中位数也可以发现这类问题。
        - 当数据集中存在个别的异常值时，可以使用最大值和最小值的统计量去审核，或者使用箱线图也可以让异常记录一目了然

:::{.notes}
准确性是指数据是否正确反映了真实情况。我们需要检查数据中是否存在错误或异常值。就像检查作业📝是否有错误答案一样。
:::

## 数据质量 - 准确性 (续)

- **举例**：
    - **拼写错误**：把“北京”写成了“背景”。
    - **数值错误**：把“100”写成了“1000”。
    - **单位错误**：把“米”写成了“厘米”。
    - **乱码**：由于编码问题，文本显示为无法识别的字符。

- **如何检查准确性**：
    - **数据可视化**：使用散点图、直方图、箱线图等可视化工具，观察数据的分布和异常值。
    - **统计分析**：计算数据的均值、中位数、标准差等统计量，检查是否有异常值。
    - **业务规则校验**：根据业务知识，检查数据是否符合常识和逻辑。
    - **数据比对**：与可靠的数据来源进行比对，检查数据是否一致。


```{python}
#| echo: false
#| label: fig-boxplot
#| fig-cap: "箱线图示例"
#| fig-alt: "一个箱线图，显示了一组数据的分布和异常值。"
import matplotlib.pyplot as plt
import numpy as np

# 生成模拟数据
np.random.seed(42)
data = np.concatenate([np.random.normal(0, 1, 950), np.random.normal(8, 2, 50)])

# 绘制箱线图
plt.figure(figsize=(8, 6))
plt.boxplot(data, showmeans=True)
plt.xlabel("数据")
plt.ylabel("值")
plt.title("箱线图")
plt.show()
```

:::{.notes}
这是一个箱线图的例子。我们可以看到，有一些点位于箱体之外，这些点可能是异常值。
:::

## 数据质量 - 及时性

- **及时性 (Timeliness)** ⏱️
    - 及时性是指数据从产生到可以查看的时间间隔，也叫数据的延时时长。
       -  **举例**: 股票的实时行情数据、天气预报数据等。
    - 及时性对于数据分析本身要求并不高，但如果数据分析周期加上数据建立的时间过长，就可能导致分析得出的结论失去了借鉴意义。就像新闻📰的时效性一样，如果新闻过时了，就没有价值了。

:::{.notes}
及时性是指数据是否及时更新。对于某些需要实时分析的数据，及时性非常重要。就像看天气预报🌤️一样，我们希望看到的是最新的预报。
:::


## 数据清洗

- 数据清洗的主要目的是对缺失值、噪声数据、不一致数据、异常数据进行处理，是对上述数据质量分析时发现的问题进行处理，使得清理后的数据格式符合标准，不存在异常数据等。就像洗菜🥬一样，把脏东西洗掉。
    - 缺失值处理
    - 噪声数据处理
    - 不一致数据的处理
    - 异常数据的处理

:::{.notes}
数据清洗是数据预处理的重要环节，它旨在解决数据质量问题，提高数据质量。就像在做菜🧑‍🍳之前要把食材洗干净一样。
:::

## 数据清洗 - 缺失值处理

- 对于缺失值，处理方法有如下几种：
    - **忽略 (Deletion)**：最简单的方式是忽略有缺失值的数据。如果某条数据记录存在缺失项，就删除该条记录，如果某个属性列缺失值过多，则在整个数据集中删除该属性，但有可能因此损失大量数据。就像扔掉烂掉的苹果🍎一样。
    - **缺失值填补 (Imputation)**：可以填补某一固定值、平均值、或者根据记录填充最有可能值，最有可能值的确定可能会利用决策树、回归分析等。就像用好的苹果🍎来替代烂掉的苹果一样。

:::{.notes}
对于缺失值，我们可以选择忽略或填补。选择哪种方法取决于缺失值的比例和数据的特点。就像修理衣服👕一样，如果破洞太大了，就只能扔掉；如果破洞比较小，就可以补一下。
:::

## 数据清洗——缺失值处理方法对比

| 方法     | 优点                                                         | 缺点                                                             | 适用场景                                                   |
| -------- | ------------------------------------------------------------ | ---------------------------------------------------------------- | ---------------------------------------------------------- |
| 忽略     | 简单易行                                                     | 可能会损失大量数据，导致信息丢失                                 | 缺失值比例很低，且缺失值不重要                             |
| 填补     | 保留了数据记录，减少信息丢失                                 | 填补值可能不准确，引入偏差                                       | 缺失值比例较高，或缺失值比较重要                           |
| 固定值填补 | 简单易行                                                   | 填补值单一，可能不符合实际情况                                   | 适用于缺失值含义明确，且可以用固定值替代的情况             |
| 平均值填补 | 利用了已有数据信息                                           | 容易受极端值影响，可能掩盖数据分布特征                           | 适用于缺失值是数值型，且数据分布比较均匀的情况             |
| 最可能值填补| 利用了数据之间的关系，填补值更接近真实值                   | 计算复杂，需要选择合适的模型                                     | 适用于缺失值与其他变量有较强关系，且有合适的模型可用的情况 |

:::{.callout-note appearance="simple"}
**举例：**

假设有一个数据集，其中“年龄”一列有缺失值。

-   **忽略**：直接删除所有年龄缺失的记录。
-   **固定值填补**：用0或-1来填充所有缺失值。
-   **平均值填补**：用所有已知年龄的平均值来填充缺失值。
-   **最可能值填补**：根据用户的其他信息（如职业、收入等），建立一个模型来预测缺失的年龄。
:::

## 数据清洗 - 噪声数据处理

-   **分箱技术 (Binning)** 🗑️
    -   通过考察相邻数据来确定最终值，可以实现异常或者噪声数据的平滑处理。基本思想是按照属性值划分子区间，如果属性值属于某个子区间，就称将其放入该子区间对应“箱子”内，即为分箱操作。箱的深度表示箱中所含数据记录条数，宽度则是对应属性值的取值范围。
    -   **举例**: 将年龄数据分成几个年龄段：0-10岁、11-20岁、21-30岁等。
-   **聚类技术 (Clustering)** 🧩
    -   将数据集合分组为由类似的数据组成的多个簇（或称为类）。聚类技术主要用于找出并清除那些落在簇之外的值（孤立点）。
    -  **举例**: 将客户按照消费习惯分成几个群体，找出与其他客户明显不同的“异常客户”。
-   **回归技术 (Regression)** 📈
    -   回归技术是通过发现两个相关的变量之间的关系，寻找适合的两个变量之间的映射关系来平滑数据，即通过建立数学模型来预测下一个数值，包括线性回归和非线性回归。
    - **举例**: 用房屋的面积、位置等特征来预测房价。

:::{.notes}
对于噪声数据，我们可以使用分箱、聚类或回归等方法进行处理。就像去除照片上的噪点一样，让照片更清晰。
:::
## 数据清洗——噪声数据处理方法对比

| 方法     | 优点                                                         | 缺点                                                   | 适用场景                                                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------ | ---------------------------------------------------------------------------------------------- |
| 分箱     | 简单易行，可以平滑数据，降低噪声影响                           | 需要确定箱子的数量和宽度，可能损失一些细节信息         | 适用于数据量较大，且噪声主要表现为小幅度波动的情况                                           |
| 聚类     | 可以自动识别离群点，不需要事先指定类别                         | 需要选择合适的聚类算法和参数，计算量可能较大             | 适用于数据中存在明显的类别结构，且噪声主要表现为离群点的情况                                   |
| 回归     | 可以利用变量之间的关系，对数据进行平滑和预测                   | 需要选择合适的回归模型，可能存在过拟合或欠拟合的风险   | 适用于数据中存在明显的趋势或模式，且噪声主要表现为随机误差的情况                               |

## 数据清洗 - 不一致数据的处理

- 对于数据质量中提到的数据不一致性问题，则需要根据实际情况来给出处理方案。就像整理房间🧹一样，把东西放到正确的位置。
- 可以使用相关材料来人工修复，违反给定规则的数据可以用知识工程的工具进行修改。
   - **举例**: 发现数据中“性别”一列既有“男/女”，又有“M/F”，需要统一成一种格式。
- 对于多个数据源集成处理时，不同数据源对某些含义相同的字段的编码规则会存在差异，此时则需要对不同数据源的数据进行数据转化。
   - **举例**: 两个数据库中都有“日期”字段，但一个用“YYYY-MM-DD”格式，另一个用“MM/DD/YYYY”格式，需要进行统一。

:::{.notes}
对于不一致数据，我们需要根据具体情况进行处理，可能需要人工干预或使用特定的工具。
:::

## 数据清洗 - 异常数据的处理

-   **不可还原异常 (Irrecoverable Anomalies)** 💥
    -   异常数据大部分情况很难修正，比如字符编码等问题引起的乱码，字符被截断，异常的数值等，这些异常数据如果没有规律可循几乎不可能被还原，只能将其直接过滤。就像破碎的花瓶💐一样，无法修复。
-   **可还原异常 (Recoverable Anomalies)** 🩹
    -   原字符中参杂了一些其他的无用字符，可以使用取子串的方法，用trim函数可以去掉字符串前后的空格等；
         - **举例**: 字符串“  Hello World  ”前后有空格，可以用`trim()`函数去掉。
    -   字符被截断的情况如果可以使用截断后字符推导出原完整字符串，那么也可以被还原。
         - **举例**: 用户名被截断为“Alexan”，可以根据其他信息推断出完整的用户名是“Alexander”。
    -   数值记录中存在异常大或者异常小的值是可以分析是否数值单位差异引起的，比如克和千克差了1000倍，这样的数值的异常可以通过转化进行处理
         - **举例**: 发现数据中有的重量单位是“克”，有的是“千克”，需要统一成一种单位。

:::{.notes}
对于异常数据，我们需要判断其是否可还原。对于不可还原的异常数据，通常直接过滤；对于可还原的异常数据，我们可以尝试修复。就像修理电器🔌一样，有些故障可以修复，有些故障则无法修复。
:::


## 特征工程

- 在很多应用中，所采集的原始数据维数很高，这些经过数据清洗后的数据成为原始特征，但并不是所有的原始特征都对于后续的分析可以直接提供信息，有些需要经过一些处理，有些甚至是干扰项。就像一堆木材🪵🪵🪵，有些可以直接用来盖房子，有些需要加工一下，有些根本就不能用。
- 特征工程是利用领域知识来处理数据创建一些特征，以便后续分析使用。目的是能够用尽量少的特征描述原始数据，同时保持原始数据与分析目的相关的特性。就像把木材加工成家具🪑🛏️🛋️一样。
    - 特征选择 (Feature Selection)
    - 特征构建 (Feature Construction)
    - 特征提取 (Feature Extraction)

:::{.notes}
特征工程是数据预处理的最后一个环节，也是非常重要的环节。它旨在从原始数据中提取出更有用的特征，以提高模型的性能。就像厨师👨‍🍳把食材切成合适的形状🔪，方便烹饪一样。
:::

## 特征工程 - 特征选择

- **特征选择的原则** 🎯
  - **特征是否发散**：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。就像所有人都是一样的身高🧍🧍🧍，那么身高这个特征就不能用来区分人。
  -   **特征是否与分析结果相关**：相关特征是指其取值能够改变分析结果。显然，与目标相关性高的特征，应当优选选择。就像要预测房价🏠，那么房屋面积、位置等特征就比房屋颜色更重要。
  -   **特征信息是否冗余**：特征中可能存在一些冗余特征，即两个特征本质上相同，也可以表示为两个特征的相关性比较高。就像“年龄”和“出生年份”这两个特征，其实表达的是同一个意思。

:::{.notes}
特征选择是指从原始特征中选择出对分析任务最有用的特征。就像挑选演员🎭一样，要选择最适合角色的演员。
:::

## 特征工程 - 特征选择 (续)

- **特征选择的方法** 🧰
    - **Filter（过滤法）**：按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。
       - **举例**: 计算每个特征的方差，选择方差大于某个阈值的特征。
    - **Wrapper（包装法）**：根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。
       - **举例**: 使用递归特征消除(Recursive Feature Elimination, RFE)算法，逐步减少特征数量，直到模型性能达到最佳。
    -   **Embedded（集成法）**：先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣
       -  **举例**: 使用LASSO回归，L1正则化会使得一部分特征的系数变为0，从而实现特征选择。

:::{.notes}
特征选择的方法有很多种，我们需要根据具体情况选择合适的方法。就像选择交通工具🚗✈️🚄一样，要根据距离、时间、预算等因素来选择。
:::

## 特征选择方法对比

| 方法       | 优点                                                                                               | 缺点                                                                                                                         | 适用场景                                                                                                                                   |
| ---------- | -------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| 过滤法     | 计算简单，速度快，不需要训练模型                                                                             | 忽略了特征之间的关系，可能选择到一些冗余的特征                                                                                       | 适用于特征维度很高，需要快速筛选特征的情况                                                                                                       |
| 包装法     | 直接针对目标函数进行优化，选择的特征子集通常效果更好                                                                   | 计算量大，容易过拟合                                                                                                         | 适用于特征维度不是很高，对模型性能要求较高的情况                                                                                                   |
| 集成法     | 结合了过滤法和包装法的优点，既考虑了特征之间的关系，又利用了模型的信息，通常效果较好                                                       | 需要训练模型，计算量可能较大                                                                                                   | 适用于特征维度较高，对模型性能要求较高的情况                                                                                                   |
## 特征工程 - 特征构建

-   特征构建是指从原始特征中人工构建新的特征。就像用积木🧱搭建城堡🏰一样，可以用已有的积木创造出新的形状。
-   特征构建需要很强的洞察力和分析能力，要求我们能够从原始数据中找出一些具有物理意义的特征。
-   假设原始数据是表格数据，可以使用混合属性或者组合属性来创建新的特征，或是分解或切分原有的特征来创建新的特征。
    -   **举例**：
        -   **混合属性**：将“年”和“月”合并成“年月”作为一个新的特征。
        -   **组合属性**：将“身高”和“体重”组合成“BMI指数”作为一个新的特征。
        -   **分解特征**：将“日期”分解成“年”、“月”、“日”、“星期几”等多个特征。
        -   **切分特征**：将“年龄”切分成“儿童”、“青年”、“中年”、“老年”等多个类别特征。

:::{.notes}
特征构建是指根据领域知识，人工构造新的特征。这需要对数据和业务有深入的理解。就像厨师👨‍🍳根据食材的特点，创造出新的菜肴🍽️一样。
:::

## 特征工程 - 特征提取

-   特征提取是在原始特征的基础上，自动构建新的特征，将原始特征转换为一组更具物理意义、统计意义或者核的特征。就像把照片📸转换成素描✏️一样，提取出照片的主要特征。方法包括主成分分析、独立成分分析和线性判别分析。
    -   **PCA (Principal Component Analysis, 主成分分析)**: PCA的思想是通过坐标轴转换，寻找数据分布的最优子空间，从而达到降维、去除数据间相关性的目的。
        -   **举例**：将1000维的人脸图像数据降维到100维，同时保留图像的主要特征。
    -   **ICA (Independent Component Analysis, 独立成分分析)**: PCA特征转换降维，提取的是不相关的部分，ICA独立成分分析，获得的是相互独立的属性
        -  **举例**：从混合的音频信号中分离出独立的声源（如人声、乐器声等）。
    -   **LDA (Linear Discriminant Analysis, 线性判别分析)**: LDA的原理是将带上标签的数据（点），通过投影的方法，投影到维度更低的空间，使得投影后的点，会形成按类别区分，相同类别的点，将会在投影后更接近，不同类别的点距离越远。
        - **举例**：将不同类别的文档映射到低维空间，使得相同主题的文档更接近，不同主题的文档更远离。

:::{.notes}
特征提取是指通过某种算法自动生成新的特征。这通常用于降维和提取数据的潜在结构。
:::



## 总结 📝

::: {layout-ncol=2}
-   今天我们学习了数据预处理的基本概念和方法。
-   数据预处理是数据分析的重要环节，它可以提高数据质量，改善模型性能。
-   数据预处理主要包括数据质量评估、数据清洗和特征工程三个方面。

:::{.callout-tip appearance="simple"}
数据预处理的流程可以概括为：

1.  **了解数据**：明确数据的类型、特征以及可能存在的问题。
2.  **数据质量评估**：评估数据的完整性、一致性、准确性和及时性。
3.  **数据清洗**：处理缺失值、噪声数据、不一致数据和异常数据。
4.  **特征工程**：从原始数据中提取有用的特征，包括特征选择、特征构建和特征提取。
:::
:::



## 思考与讨论 🤔

-   在你自己的学习或工作中，遇到过哪些数据质量问题？你是如何处理的？
-   除了本章介绍的方法，你还知道哪些数据预处理的方法？
-   如何评价一个数据预处理方案的好坏？

:::{.notes}
请大家结合自己的经验，思考并讨论以上问题。
:::


